So with a lot of data Hadoop needs a way to store it reliably across a fleet of machines. Thats what the HDFS does.

HDFS is a distributed filesystem, optimised for read heavy workloads.

## Blocks
Blocks are the min unit for reading and writing data. Disk blocks are usually 512 and file blcoks are usually few KB. Hadoop blocks are usually 128MB. Big HDFS blocks to reduce time spent doing disk seeks to start of block.

```
How to list blocks:
hdfs fsck / -files -blocks
```

## Namenodes and Datanodes
HDFS has two types of nodes operating in master worker pattern. Namenodes are masters, datanodes are workers.

Namenode
- Managers filesystem namespace
- Maintains filesystem tree and metadata for all files and directories
- Maintains what datanodes have what blocks
- Persisted to disk as namespace image and edit log

Datanode
- Store, retrieve blocks
- Report to namenode with lists of blocks they store

When the namenode is lost, we're fucked
- So we can write namenode info to multiple filesystems
- And have a secondary namenode which just periodically merges namespace image with edit log. Fancy way to say that it does checkpointing.

We can run multiple namenodes that each manage a namespace volume
- Just partitioning

We can also run multiple nodes for higher availability
- One is on standby
- The two nodes need highly available shared storage for edit log, usually using Quorum Journal Manager that runs a few journal nodes, where each log is committed to the majority of nodes. Similar to ZooKeeper.
- Having multiple nodes is a pain when a node goes down. Failover controller just manages this, still has to go to great lengths in ungracegful handover to stop misbehaving node at all costs.
